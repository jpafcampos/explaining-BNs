{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4eec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import HillClimbSearch\n",
    "from pgmpy.estimators import BDeuScore, K2Score, BicScore\n",
    "from pgmpy.metrics import structure_score\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.estimators import ScoreCache\n",
    "from pgmpy.inference.CausalInference import CausalInference\n",
    "import networkx as nx\n",
    "import bnlearn as bn\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94ec9f",
   "metadata": {},
   "source": [
    "# Brute Force exact SDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d67f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_sdp_bruteforce(model, D, d_value, evidence, threshold):\n",
    "    \"\"\"\n",
    "    Exact brute-force computation of Same-Decision Probability (SDP).\n",
    "    \n",
    "    Parameters:\n",
    "        model      : pgmpy Bayesian model\n",
    "        D          : decision variable name (string)\n",
    "        d_value    : state of D to test (e.g., 1 or 'yes')\n",
    "        evidence   : dict of observed variables {var: value}\n",
    "        threshold  : decision threshold T\n",
    "        \n",
    "    Returns:\n",
    "        sdp (float)\n",
    "    \"\"\"\n",
    "    # 1. Identify hidden variables (H)\n",
    "    all_vars = set(model.nodes())\n",
    "    observed_vars = set(evidence.keys())\n",
    "    H = list(all_vars - observed_vars - {D})\n",
    "    \n",
    "    inference = VariableElimination(model)\n",
    "\n",
    "    # 2. Determine the CURRENT decision (F(Pr(D|e)))\n",
    "    # We must know if we are currently above or below the threshold\n",
    "    current_dist = inference.query(variables=[D], evidence=evidence, show_progress=False)\n",
    "    d_index = model.get_cpds(D).state_names[D].index(d_value)\n",
    "    p_d_initial = current_dist.values[d_index]\n",
    "    \n",
    "    # The decision function F returns 1 if >= threshold, else 0\n",
    "    current_decision = p_d_initial >= threshold\n",
    "\n",
    "    # 3. Setup hidden variable state space\n",
    "    state_spaces = [model.get_cpds(var).state_names[var] for var in H]\n",
    "    all_assignments = list(itertools.product(*state_spaces))\n",
    "\n",
    "    # 4. Pre-compute P(H | e) to get the weights for each scenario\n",
    "    p_h_dist = inference.query(variables=H, evidence=evidence, show_progress=False)\n",
    "\n",
    "    sdp = 0.0\n",
    "\n",
    "    # 5. Iterate through all possible hidden variable instantiations (h)\n",
    "    for assignment in all_assignments:\n",
    "        h_dict = dict(zip(H, assignment))\n",
    "\n",
    "        # Get the probability of this specific scenario: Pr(h | e)\n",
    "        p_h_given_e = p_h_dist.get_value(**h_dict)\n",
    "\n",
    "        if p_h_given_e == 0:\n",
    "            continue\n",
    "\n",
    "        # 6. Compute the NEW probability: Pr(d | e, h)\n",
    "        query_e_h = {**evidence, **h_dict}\n",
    "        p_d_given_e_h_dist = inference.query(\n",
    "            variables=[D],\n",
    "            evidence=query_e_h,\n",
    "            show_progress=False\n",
    "        )\n",
    "        p_d_given_e_h = p_d_given_e_h_dist.values[d_index]\n",
    "\n",
    "        # 7. Check if the decision is the SAME: [F(Pr(D|e,h)) == F(Pr(D|e))]\n",
    "        new_decision = p_d_given_e_h >= threshold\n",
    "        \n",
    "        if new_decision == current_decision:\n",
    "            sdp += p_h_given_e\n",
    "\n",
    "    return sdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb25c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/asia10K.csv\")\n",
    "data = data.replace({'yes': 1, 'no': 0})\n",
    "data.rename(columns={\n",
    "    'Smoker': 'S',\n",
    "    'LungCancer': 'L',\n",
    "    'VisitToAsia': 'A',\n",
    "    'Tuberculosis': 'T',\n",
    "    'TuberculosisOrCancer': 'E',\n",
    "    'X-ray': 'X',\n",
    "    'Bronchitis': 'B',\n",
    "    'Dyspnea': 'D'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088d6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "asia_graph = BayesianModel([('A', 'T'), ('S', 'L'), ('S', 'B'), ('L', 'E'), ('T', 'E'), ('E', 'X'), ('E', 'D'), ('B', 'D')])\n",
    "asia_graph.fit(data, estimator=MaximumLikelihoodEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5141b47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('A', 'T', 'S', 'L', 'B', 'E', 'X', 'D'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asia_graph.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "713ae8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp = exact_sdp_bruteforce(asia_graph, D='B', d_value=1, evidence={'D': 1, 'A': 1}, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b51d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317318433235299"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2deb6827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure 3 from 2014 paper to test SDP calculation\n",
    "\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "\n",
    "model = BayesianNetwork([('D','S1'), ('D','S2')])\n",
    "\n",
    "# Prior\n",
    "cpd_D = TabularCPD(\n",
    "    variable='D',\n",
    "    variable_card=2,\n",
    "    values=[[0.5],[0.5]],\n",
    "    state_names={'D':['+','-']}\n",
    ")\n",
    "\n",
    "# S1\n",
    "cpd_S1 = TabularCPD(\n",
    "    variable='S1',\n",
    "    variable_card=2,\n",
    "    values=[\n",
    "        [0.2, 0.8],   # S1=-\n",
    "        [0.8, 0.2]    # S1=+\n",
    "    ],\n",
    "    evidence=['D'],\n",
    "    evidence_card=[2],\n",
    "    state_names={'S1':['-','+'], 'D':['+','-']}\n",
    ")\n",
    "\n",
    "# S2 (3 states)\n",
    "cpd_S2 = TabularCPD(\n",
    "    variable='S2',\n",
    "    variable_card=3,\n",
    "    values=[\n",
    "        [0.05, 0.75],  # -\n",
    "        [0.20, 0.20],  # o\n",
    "        [0.75, 0.05]   # +\n",
    "    ],\n",
    "    evidence=['D'],\n",
    "    evidence_card=[2],\n",
    "    state_names={'S2':['-','o','+'], 'D':['+','-']}\n",
    ")\n",
    "\n",
    "model.add_cpds(cpd_D, cpd_S1, cpd_S2)\n",
    "model.check_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591d9a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(S2='+' | D=+): 0.75\n",
      "P(S2='+' | D=-): 0.05\n"
     ]
    }
   ],
   "source": [
    "# compute P(S2='+' | D=+) and P(S2='+' | D=-\n",
    "inference = VariableElimination(model)\n",
    "p_s2_plus_given_d_plus = inference.query(variables=['S2'], evidence={'D': '+'}, show_progress=False).values[2]\n",
    "p_s2_plus_given_d_minus = inference.query(variables=['S2'], evidence={'D': '-'}, show_progress=False).values[2]\n",
    "print(\"P(S2='+' | D=+):\", p_s2_plus_given_d_plus)\n",
    "print(\"P(S2='+' | D=-):\", p_s2_plus_given_d_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e2a255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(S1='+' | D=+): 0.8\n",
      "P(S1='+' | D=-): 0.2\n"
     ]
    }
   ],
   "source": [
    "# compute P(S1=+ | D=+) and P(S1=+ | D=-)\n",
    "inference = VariableElimination(model)\n",
    "p_s1_plus_given_d_plus = inference.query(variables=['S1'], evidence={'D': '+'}, show_progress=False).values[1]\n",
    "p_s1_plus_given_d_minus = inference.query(variables=['S1'], evidence={'D': '-'}, show_progress=False).values[1]\n",
    "print(\"P(S1='+' | D=+):\", p_s1_plus_given_d_plus)\n",
    "print(\"P(S1='+' | D=-):\", p_s1_plus_given_d_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e19fb311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(S2='o' | D=+): 0.2\n",
      "P(S2='o' | D=-): 0.2\n"
     ]
    }
   ],
   "source": [
    "# compute P(S2='o'| D=+) and P(S2='o'| D=-)\n",
    "p_s2_o_given_d_plus = inference.query(variables=['S2'], evidence={'D': '+'}, show_progress=False).values[1]\n",
    "p_s2_o_given_d_minus = inference.query(variables=['S2'], evidence={'D': '-'}, show_progress=False).values[1]\n",
    "print(\"P(S2='o' | D=+):\", p_s2_o_given_d_plus)\n",
    "print(\"P(S2='o' | D=-):\", p_s2_o_given_d_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3ad36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial SDP: 0.7625\n"
     ]
    }
   ],
   "source": [
    "sdp_initial = exact_sdp_bruteforce(\n",
    "    model,\n",
    "    D='D',\n",
    "    d_value='+',\n",
    "    evidence={'S2':'+'},\n",
    "    threshold=0.8\n",
    ")\n",
    "\n",
    "print(\"Initial SDP:\", sdp_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb4261",
   "metadata": {},
   "source": [
    "# Boostrap SDP estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00fbfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapped_sdp_estimation(model, D, d_value, evidence, threshold, n_samples=100, n_bootstraps=50):\n",
    "    \"\"\"\n",
    "    Estimates SDP variance by sampling hidden variable configurations.\n",
    "    \"\"\"\n",
    "    # 1. Identify hidden variables (H)\n",
    "    all_vars = set(model.nodes())\n",
    "    observed_vars = set(evidence.keys())\n",
    "    H = list(all_vars - observed_vars - {D})\n",
    "    \n",
    "    inference = VariableElimination(model)\n",
    "    d_index = model.get_cpds(D).state_names[D].index(d_value)\n",
    "\n",
    "    # 2. Determine the CURRENT decision F(Pr(D|e))\n",
    "    current_dist = inference.query(variables=[D], evidence=evidence, show_progress=False)\n",
    "    current_decision = current_dist.values[d_index] >= threshold\n",
    "\n",
    "    # 3. Get the conditional distribution P(H | e)\n",
    "    # This is the \"population\" we sample from\n",
    "    p_h_dist = inference.query(variables=H, evidence=evidence, show_progress=False)\n",
    "    \n",
    "    # Flatten the distribution into a list of assignments and their probabilities\n",
    "    # pgmpy's DiscreteFactor.values is a multi-dimensional array\n",
    "    h_states = [model.get_cpds(var).state_names[var] for var in H]\n",
    "    \n",
    "    # Create a dataframe of all possible H configurations and their probabilities\n",
    "    import itertools\n",
    "    all_configs = list(itertools.product(*h_states))\n",
    "    probabilities = p_h_dist.values.flatten()\n",
    "    \n",
    "    # Filter out zero-probability states to speed up sampling\n",
    "    valid_indices = np.where(probabilities > 0)[0]\n",
    "    filtered_configs = [all_configs[i] for i in valid_indices]\n",
    "    filtered_probs = probabilities[valid_indices]\n",
    "    filtered_probs /= filtered_probs.sum() # Normalize to ensure it sums to 1\n",
    "\n",
    "    sdp_estimates = []\n",
    "\n",
    "    for b in range(n_bootstraps):\n",
    "        # 4. Uniformly sample a subset of hidden configurations\n",
    "        # Note: We sample from the 'possibilities' then weigh by their actual P(h|e)\n",
    "        # OR we sample according to P(h|e) and just count matches. \n",
    "        # Sampling according to P(h|e) is usually more efficient for variance study.\n",
    "        indices = np.random.choice(len(filtered_configs), size=n_samples, p=filtered_probs)\n",
    "        \n",
    "        matches = 0\n",
    "        for idx in indices:\n",
    "            h_dict = dict(zip(H, filtered_configs[idx]))\n",
    "            \n",
    "            # 5. Compute Pr(d | e, h)\n",
    "            query_e_h = {**evidence, **h_dict}\n",
    "            p_d_given_e_h_dist = inference.query([D], evidence=query_e_h, show_progress=False)\n",
    "            new_decision = p_d_given_e_h_dist.values[d_index] >= threshold\n",
    "            \n",
    "            if new_decision == current_decision:\n",
    "                matches += 1\n",
    "        \n",
    "        # 6. SDP Estimate for this bootstrap run\n",
    "        sdp_estimates.append(matches / n_samples)\n",
    "\n",
    "    return np.array(sdp_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dca70554",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_estimates = bootstrapped_sdp_estimation(asia_graph, D='B', d_value=1, evidence={'D': 1, 'A': 1}, threshold=0.5, n_samples=100, n_bootstraps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a99ecb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96, 0.91, 0.95, 0.93, 0.94, 0.96, 0.9 , 0.93, 0.95, 0.95, 0.97,\n",
       "       0.89, 0.93, 0.95, 0.93, 0.91, 0.94, 0.91, 0.95, 0.97, 0.95, 0.95,\n",
       "       0.95, 0.95, 0.93, 0.93, 0.94, 0.94, 0.96, 0.95, 0.95, 0.9 , 0.97,\n",
       "       0.92, 0.92, 0.96, 0.95, 0.92, 0.92, 0.92, 0.9 , 0.9 , 0.93, 0.96,\n",
       "       0.97, 0.94, 0.93, 0.94, 0.87, 0.94])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "317b2e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot estimates histogram\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sdp_estimates, bins=10, edgecolor='black')\n",
    "plt.title('Bootstrap SDP Estimates')\n",
    "plt.xlabel('SDP Estimate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2a4b8",
   "metadata": {},
   "source": [
    "# Tree Search exact SDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1744ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partitions(model, H, D, E):\n",
    "    \"\"\"\n",
    "    Finds independent partitions of H given D and E by pruning the network structure.\n",
    "    Based on Section 5.2.1 of Chen, Choi, & Darwiche (2014).\n",
    "    \"\"\"\n",
    "    # Create a directed graph from the model\n",
    "    G = nx.DiGraph(model.edges())\n",
    "    \n",
    "    # 1. Delete edges outgoing from nodes in evidence E and hypothesis D\n",
    "    nodes_to_cut = set(E.keys()) | {D}\n",
    "    for node in nodes_to_cut:\n",
    "        if node in G:\n",
    "            edges_to_remove = list(G.out_edges(node))\n",
    "            G.remove_edges_from(edges_to_remove)\n",
    "            \n",
    "    # 2. Successively delete all leaf nodes that are neither in H, E, or D\n",
    "    keep_nodes = set(H) | set(E.keys()) | {D}\n",
    "    while True:\n",
    "        # A node is a leaf if out_degree is 0\n",
    "        leaves = [n for n, d in G.out_degree() if d == 0 and n not in keep_nodes]\n",
    "        if not leaves:\n",
    "            break\n",
    "        G.remove_nodes_from(leaves)\n",
    "        \n",
    "    # 3. Identify weakly connected components to form partitions S_i\n",
    "    components = list(nx.weakly_connected_components(G))\n",
    "    \n",
    "    # Extract only the variables in H for each component\n",
    "    partitions = []\n",
    "    for comp in components:\n",
    "        s_i = list(set(comp) & set(H))\n",
    "        if s_i:  # Only keep non-empty partitions\n",
    "            partitions.append(s_i)\n",
    "            \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "668e0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_sdp_tree_search(model, D, d_value, evidence, threshold):\n",
    "    \"\"\"\n",
    "    Exact computation of SDP for arbitrary networks using partitions.\n",
    "    Implements the generalized approach from Section 5.2.\n",
    "    \"\"\"\n",
    "    inference = VariableElimination(model)\n",
    "    \n",
    "    all_vars = set(model.nodes())\n",
    "    observed_vars = set(evidence.keys())\n",
    "    H = list(all_vars - observed_vars - {D})\n",
    "    \n",
    "    # Get opposite state for D\n",
    "    d_states = model.get_cpds(D).state_names[D]\n",
    "    d_index = d_states.index(d_value)\n",
    "    not_d_value = d_states[1] if d_index == 0 else d_states[0]\n",
    "\n",
    "    # 1. Compute Initial Log-Odds and Lambda\n",
    "    initial_dist = inference.query(variables=[D], evidence=evidence, show_progress=False)\n",
    "    p_d_e = initial_dist.get_value(**{D: d_value})\n",
    "    p_not_d_e = initial_dist.get_value(**{D: not_d_value})\n",
    "    \n",
    "    log_O_d_e = math.log(p_d_e / p_not_d_e) if p_not_d_e > 0 else float('inf')\n",
    "    lambda_threshold = math.log(threshold / (1 - threshold))\n",
    "    current_decision_positive = (log_O_d_e >= lambda_threshold)\n",
    "\n",
    "    # 2. Get Partitions S_1, ..., S_k\n",
    "    partitions = get_partitions(model, H, D, evidence)\n",
    "    \n",
    "    # 3. Compute Weights of Evidence for all Aggregate Attributes S_i\n",
    "    weights = []\n",
    "    for s_i in partitions:\n",
    "        s_i_weights = {}\n",
    "        # Get all state combinations for the variables in this partition\n",
    "        state_spaces = [model.get_cpds(var).state_names[var] for var in s_i]\n",
    "        all_s_i_assignments = list(itertools.product(*state_spaces))\n",
    "        \n",
    "        # Query joint distribution of S_i given D and e\n",
    "        dist_given_d = inference.query(variables=s_i, evidence={**evidence, D: d_value}, show_progress=False)\n",
    "        dist_given_not_d = inference.query(variables=s_i, evidence={**evidence, D: not_d_value}, show_progress=False)\n",
    "        \n",
    "        for assignment in all_s_i_assignments:\n",
    "            assign_dict = dict(zip(s_i, assignment))\n",
    "            \n",
    "            p_s_d = dist_given_d.get_value(**assign_dict)\n",
    "            p_s_not_d = dist_given_not_d.get_value(**assign_dict)\n",
    "            \n",
    "            p_s_d = max(p_s_d, 1e-9)\n",
    "            p_s_not_d = max(p_s_not_d, 1e-9)\n",
    "            \n",
    "            # Using tuple as dictionary key to represent the joint state\n",
    "            s_i_weights[tuple(assignment)] = math.log(p_s_d / p_s_not_d)\n",
    "            \n",
    "        weights.append({\n",
    "            'vars': s_i,\n",
    "            'weights': s_i_weights,\n",
    "            'max': max(s_i_weights.values()),\n",
    "            'min': min(s_i_weights.values())\n",
    "        })\n",
    "\n",
    "    # Order partitions by max upper/lower bound difference for better pruning\n",
    "    weights.sort(key=lambda w: w['max'] - w['min'], reverse=True)\n",
    "\n",
    "    # 4. DFS Function with Aggregate Attributes\n",
    "    def dfs_sdp(q_dict, depth):\n",
    "        # Calculate current log odds\n",
    "        w_q = 0\n",
    "        for i in range(depth):\n",
    "            s_vars = weights[i]['vars']\n",
    "            s_assignment = tuple(q_dict[v] for v in s_vars)\n",
    "            w_q += weights[i]['weights'][s_assignment]\n",
    "            \n",
    "        current_log_odds = log_O_d_e + w_q\n",
    "        \n",
    "        # Calculate Bounds using remaining partitions\n",
    "        remaining_max = sum(w['max'] for w in weights[depth:])\n",
    "        remaining_min = sum(w['min'] for w in weights[depth:])\n",
    "        \n",
    "        upper_bound = current_log_odds + remaining_max\n",
    "        lower_bound = current_log_odds + remaining_min\n",
    "        \n",
    "        def get_prob_q():\n",
    "            if not q_dict: return 1.0\n",
    "            dist = inference.query(variables=list(q_dict.keys()), evidence=evidence, show_progress=False)\n",
    "            return dist.get_value(**q_dict)\n",
    "\n",
    "        # --- PRUNING LOGIC ---\n",
    "        if current_decision_positive:\n",
    "            if lower_bound >= lambda_threshold: return get_prob_q()\n",
    "            if upper_bound < lambda_threshold: return 0.0\n",
    "        else:\n",
    "            if upper_bound < lambda_threshold: return get_prob_q()\n",
    "            if lower_bound >= lambda_threshold: return 0.0\n",
    "        \n",
    "        if depth == len(weights):\n",
    "            is_positive = current_log_odds >= lambda_threshold\n",
    "            if is_positive == current_decision_positive:\n",
    "                return get_prob_q()\n",
    "            return 0.0\n",
    "            \n",
    "        # Recursive Step over the Aggregate Attribute (Partition)\n",
    "        s_vars = weights[depth]['vars']\n",
    "        state_spaces = [model.get_cpds(var).state_names[var] for var in s_vars]\n",
    "        all_s_i_assignments = list(itertools.product(*state_spaces))\n",
    "        \n",
    "        total_sdp = 0.0\n",
    "        for assignment in all_s_i_assignments:\n",
    "            new_q = q_dict.copy()\n",
    "            for var, state in zip(s_vars, assignment):\n",
    "                new_q[var] = state\n",
    "            total_sdp += dfs_sdp(new_q, depth + 1)\n",
    "            \n",
    "        return total_sdp\n",
    "\n",
    "    return dfs_sdp({}, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f670706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_tree_search_sdp(model, D, d_value, evidence, threshold, partitions):\n",
    "    \"\"\"\n",
    "    Highly optimized exact SDP computation. \n",
    "    Removes pgmpy inference from the DFS loop by leveraging conditional independence.\n",
    "    \"\"\"\n",
    "    inference = VariableElimination(model)\n",
    "    \n",
    "    # Get opposite state for D\n",
    "    d_states = model.get_cpds(D).state_names[D]\n",
    "    d_index = d_states.index(d_value)\n",
    "    not_d_value = d_states[1] if d_index == 0 else d_states[0]\n",
    "\n",
    "    # 1. Compute Initial Log-Odds and Lambda\n",
    "    initial_dist = inference.query(variables=[D], evidence=evidence, show_progress=False)\n",
    "    p_d_e = initial_dist.get_value(**{D: d_value})\n",
    "    p_not_d_e = initial_dist.get_value(**{D: not_d_value})\n",
    "    print(f\"Initial P(D|e): {p_d_e}, P(not D|e): {p_not_d_e}\")\n",
    "    \n",
    "    log_O_d_e = math.log(p_d_e / p_not_d_e) if p_not_d_e > 0 else float('inf')\n",
    "    lambda_threshold = math.log(threshold / (1 - threshold))\n",
    "    current_decision_positive = (log_O_d_e >= lambda_threshold)\n",
    "    print(f\"Initial Log-Odds: {log_O_d_e}, Lambda: {lambda_threshold}, Current Decision Positive: {current_decision_positive}\")\n",
    "\n",
    "    # 2. Precompute all probabilities and weights outside the search tree\n",
    "    partitions_data = []\n",
    "    \n",
    "    for s_i in partitions:\n",
    "        state_spaces = [model.get_cpds(var).state_names[var] for var in s_i]\n",
    "        all_s_i_assignments = list(itertools.product(*state_spaces))\n",
    "        \n",
    "        # Query joint distribution of S_i given D and e\n",
    "        dist_given_d = inference.query(variables=s_i, evidence={**evidence, D: d_value}, show_progress=False)\n",
    "        dist_given_not_d = inference.query(variables=s_i, evidence={**evidence, D: not_d_value}, show_progress=False)\n",
    "        \n",
    "        states_info = []\n",
    "        max_w = -float('inf')\n",
    "        min_w = float('inf')\n",
    "        \n",
    "        for assignment in all_s_i_assignments:\n",
    "            assign_dict = dict(zip(s_i, assignment))\n",
    "            \n",
    "            p_s_d = max(dist_given_d.get_value(**assign_dict), 1e-12)\n",
    "            p_s_not_d = max(dist_given_not_d.get_value(**assign_dict), 1e-12)\n",
    "            \n",
    "            w = math.log(p_s_d / p_s_not_d)\n",
    "            max_w = max(max_w, w)\n",
    "            min_w = min(min_w, w)\n",
    "            \n",
    "            states_info.append({\n",
    "                'w': w,\n",
    "                'p_d': p_s_d,\n",
    "                'p_not_d': p_s_not_d\n",
    "            })\n",
    "            \n",
    "        partitions_data.append({\n",
    "            'states': states_info,\n",
    "            'max_w': max_w,\n",
    "            'min_w': min_w\n",
    "        })\n",
    "\n",
    "    # Sort partitions by max variance for optimal early pruning\n",
    "    partitions_data.sort(key=lambda x: x['max_w'] - x['min_w'], reverse=True)\n",
    "\n",
    "    # 3. Precompute Suffix Sums for O(1) bound lookups\n",
    "    n_parts = len(partitions_data)\n",
    "    suffix_max = [0] * (n_parts + 1)\n",
    "    suffix_min = [0] * (n_parts + 1)\n",
    "    \n",
    "    for i in range(n_parts - 1, -1, -1):\n",
    "        suffix_max[i] = suffix_max[i+1] + partitions_data[i]['max_w']\n",
    "        suffix_min[i] = suffix_min[i+1] + partitions_data[i]['min_w']\n",
    "\n",
    "    # 4. Lightning-Fast DFS\n",
    "    def dfs(depth, current_log_odds, prob_cond_d, prob_cond_not_d):\n",
    "        # O(1) Bound calculations\n",
    "        upper_bound = current_log_odds + suffix_max[depth]\n",
    "        lower_bound = current_log_odds + suffix_min[depth]\n",
    "        \n",
    "        # O(1) Probability calculation leveraging conditional independence\n",
    "        def get_prob_q():\n",
    "            return (p_d_e * prob_cond_d) + (p_not_d_e * prob_cond_not_d)\n",
    "\n",
    "        # --- PRUNING LOGIC ---\n",
    "        if current_decision_positive:\n",
    "            if lower_bound >= lambda_threshold: return get_prob_q()\n",
    "            if upper_bound < lambda_threshold: return 0.0\n",
    "        else:\n",
    "            if upper_bound < lambda_threshold: return get_prob_q()\n",
    "            if lower_bound >= lambda_threshold: return 0.0\n",
    "        \n",
    "        # Leaf node evaluation\n",
    "        if depth == n_parts:\n",
    "            is_positive = current_log_odds >= lambda_threshold\n",
    "            if is_positive == current_decision_positive:\n",
    "                return get_prob_q()\n",
    "            return 0.0\n",
    "            \n",
    "        # Recursive Step passing state as arguments (no dict copies needed)\n",
    "        total_sdp = 0.0\n",
    "        for state_data in partitions_data[depth]['states']:\n",
    "            total_sdp += dfs(\n",
    "                depth + 1,\n",
    "                current_log_odds + state_data['w'],\n",
    "                prob_cond_d * state_data['p_d'],\n",
    "                prob_cond_not_d * state_data['p_not_d']\n",
    "            )\n",
    "            \n",
    "        return total_sdp\n",
    "\n",
    "    # Start DFS with base probabilities of 1.0 (multiplicative identity)\n",
    "    return dfs(0, log_O_d_e, 1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "790d3113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7625\n"
     ]
    }
   ],
   "source": [
    "sdp = exact_sdp_tree_search(\n",
    "    model,\n",
    "    D='D',\n",
    "    d_value='+',\n",
    "    evidence={'S2':'+'},\n",
    "    threshold=0.8\n",
    ")\n",
    "print(sdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84b6bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial P(D|e): 0.9375, P(not D|e): 0.0625\n",
      "Initial Log-Odds: 2.70805020110221, Lambda: 1.3862943611198908, Current Decision Positive: True\n",
      "0.7625\n"
     ]
    }
   ],
   "source": [
    "sdp = optimized_tree_search_sdp(\n",
    "    model,\n",
    "    D='D',\n",
    "    d_value='+',\n",
    "    evidence={'S2':'+'},\n",
    "    threshold=0.8,\n",
    "    partitions=get_partitions(model, ['S1'], 'D', {'S2': '+'})\n",
    ")\n",
    "print(sdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "148e6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDP for Asia graph: 0.9317318433235299\n"
     ]
    }
   ],
   "source": [
    "sdp = exact_sdp_tree_search(asia_graph, D='B', d_value=1, evidence={'D': 1, 'A': 1}, threshold=0.5)\n",
    "print(\"SDP for Asia graph:\", sdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58989dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_figure_7_partitions():\n",
    "    # 1. Define the network structure based on Figure 7\n",
    "    edges = [\n",
    "        ('E1', 'X1'), ('E1', 'D'),\n",
    "        ('D', 'X1'), ('D', 'H1'), ('D', 'H3'), ('D', 'E2'), ('D', 'X3'),\n",
    "        ('H4', 'D'),\n",
    "        ('X1', 'H1'),\n",
    "        ('H1', 'X2'), ('H1', 'H2'),\n",
    "        ('X2', 'H2'), ('X2', 'H3'),\n",
    "        ('H3', 'E2'),\n",
    "        ('E2', 'X3'), ('E2', 'H6'),\n",
    "        ('H5', 'X3'),\n",
    "        ('X3', 'H6')\n",
    "    ]\n",
    "    \n",
    "    model = BayesianNetwork(edges)\n",
    "    \n",
    "    # 2. Define our sets based on the paper\n",
    "    # D is the decision variable, E are the observed evidence, H are the hidden variables\n",
    "    decision_var = 'D'\n",
    "    evidence = {'E1': 1, 'E2': 1} # The actual values don't matter for the structure pruning\n",
    "    hidden_vars = ['H1', 'H2', 'H3', 'H4', 'H5', 'H6']\n",
    "    \n",
    "    # 3. Run the partitioning algorithm\n",
    "    print(\"Running partitioning on Figure 7 network...\")\n",
    "    partitions = get_partitions(model, hidden_vars, decision_var, evidence)\n",
    "    \n",
    "    # 4. Display the results\n",
    "    for i, part in enumerate(partitions, 1):\n",
    "        # Sorting just for cleaner display output\n",
    "        print(f\"S{i} = {sorted(part)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c70665a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running partitioning on Figure 7 network...\n",
      "S1 = ['H1', 'H2', 'H3']\n",
      "S2 = ['H4']\n",
      "S3 = ['H5', 'H6']\n"
     ]
    }
   ],
   "source": [
    "test_figure_7_partitions() # tested and works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91ab90",
   "metadata": {},
   "source": [
    "# Lower Bound computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a35a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sdp_lower_bound(model, inference, D, d_value, evidence, threshold):\n",
    "    \"\"\"\n",
    "    Estimates the Same-Decision Probability (SDP) bound using exact variance \n",
    "    and the one-sided Chebyshev inequality.\n",
    "    \"\"\"\n",
    "    # Identify hidden variables (H)\n",
    "    all_vars = set(model.nodes())\n",
    "    observed_vars = set(evidence.keys())\n",
    "    H = list(all_vars - observed_vars - {D})\n",
    "\n",
    "    # 1. Compute E[Q(H)] = Pr(d | e) directly\n",
    "    dist_D = inference.query(variables=[D], evidence=evidence, show_progress=False)\n",
    "    d_index = model.get_cpds(D).state_names[D].index(d_value)\n",
    "    EQ = dist_D.values[d_index] \n",
    "\n",
    "    # 2. Compute Pr(H | e) to look up state probabilities\n",
    "    dist_H_given_e = inference.query(variables=H, evidence=evidence, show_progress=False)\n",
    "\n",
    "    state_spaces = [model.get_cpds(var).state_names[var] for var in H]\n",
    "    all_assignments = list(itertools.product(*state_spaces))\n",
    "\n",
    "    EQ2 = 0.0\n",
    "\n",
    "    # 3. Iterate over all combinations of h to find E[Q(H)^2]\n",
    "    for assignment in all_assignments:\n",
    "        h_dict = dict(zip(H, assignment))\n",
    "        \n",
    "        # Look up Pr(h | e) from our pre-computed distribution\n",
    "        # Note: In pgmpy, extracting specific joint states can be done via reduce\n",
    "        p_h_given_e = dist_H_given_e.copy()\n",
    "        p_h_given_e.reduce(list(h_dict.items()))\n",
    "        p_h_given_e_val = p_h_given_e.values.item()\n",
    "\n",
    "        if p_h_given_e_val == 0:\n",
    "            continue\n",
    "\n",
    "        query_e_h = evidence.copy()\n",
    "        query_e_h.update(h_dict)\n",
    "\n",
    "        # Compute Q(h) = Pr(d | e, h)\n",
    "        q_dist = inference.query(variables=[D], evidence=query_e_h, show_progress=False)\n",
    "        q_val = q_dist.values[d_index]\n",
    "\n",
    "        EQ2 += (q_val ** 2) * p_h_given_e_val\n",
    "\n",
    "    # 4. Compute Variance\n",
    "    variance = EQ2 - (EQ ** 2)\n",
    "\n",
    "    # 5. Apply the one-sided Chebyshev inequality\n",
    "    # Bound formula: Var / (Var + (E[Q] - T)^2)\n",
    "    if EQ >= threshold:\n",
    "        # Decision confirmed: we want P(Q(H) >= T)\n",
    "        sdp_bound = 1 - (variance / (variance + (EQ - threshold)**2))\n",
    "    else:\n",
    "        # Decision rejected: we want P(Q(H) <= T)\n",
    "        sdp_bound = 1 - (variance / (variance + (threshold - EQ)**2))\n",
    "\n",
    "    return sdp_bound, variance, EQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ff60f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated SDP Bound: 0.7948101207153082, Variance: 0.023984248065152758, Mean: 0.8048012754399733\n"
     ]
    }
   ],
   "source": [
    "lb, var, mean = estimate_sdp_lower_bound(asia_graph, VariableElimination(asia_graph), D='B', d_value=1, evidence={'D': 1, 'A': 1}, threshold=0.5)\n",
    "print(f\"Estimated SDP Bound: {lb}, Variance: {var}, Mean: {mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a8272",
   "metadata": {},
   "source": [
    "# Testing Child network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e1a78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "child = pd.read_csv(\"/home/joao/Desktop/UFMG/PhD/code/explaining-BN/data/child.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdfc683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground truth DAG\n",
    "child_graph = nx.read_gml(\"/home/joao/Desktop/UFMG/PhD/code/explaining-BN/data/child.gml\")\n",
    "# convert to pgmpy format\n",
    "edges = list(child_graph.edges())\n",
    "child_model = BayesianNetwork(edges)\n",
    "child_model.fit(child, estimator=MaximumLikelihoodEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d137781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Disease=1 | evidence) for patient 1: 0.7032479869718629\n"
     ]
    }
   ],
   "source": [
    "patient1 = {'Disease': 1, 'ChestXray': 1, 'CO2Report': 0, 'XrayReport': 1}\n",
    "target = 'Sick'\n",
    "# P(Disease=1 | evidence) for patient 1\n",
    "inference_child = VariableElimination(child_model)\n",
    "p_disease_given_evidence = inference_child.query(variables=[target], evidence=patient1, show_progress=False).values[1]\n",
    "print(f\"P(Disease=1 | evidence) for patient 1: {p_disease_given_evidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0ba7dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial P(D|e): 0.7032479869718629, P(not D|e): 0.29675201302813714\n",
      "Initial Log-Odds: 0.8628127678520303, Lambda: 0.0, Current Decision Positive: True\n",
      "SDP for patient 1: 0.9440456390425063\n"
     ]
    }
   ],
   "source": [
    "#H_child = set(model_child.nodes()) - set(patient1.keys()) - {target}\n",
    "H_child = ['DuctFlow', 'CO2', 'Age', 'BirthAsphyxia', \n",
    "           'LVHReport', 'LowerBodyO2', 'LungFlow', 'Grunting', 'LungParench', 'CardiacMixing', 'LVH']\n",
    "sdp_patient1 = optimized_tree_search_sdp(\n",
    "    child_model,\n",
    "    D=target,\n",
    "    d_value=1,\n",
    "    evidence=patient1,\n",
    "    threshold=0.5, # USANDO 0.5 O SDP NAO MUDA EM FUNCAO DO D VALUE\n",
    "    partitions=get_partitions(child_model, H_child, target, patient1)\n",
    ")\n",
    "print(f\"SDP for patient 1: {sdp_patient1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f8c903d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1 = ['CO2', 'CardiacMixing', 'DuctFlow', 'Grunting', 'GruntingReport', 'HypDistrib', 'HypoxiaInO2', 'LowerBodyO2', 'LungFlow', 'LungParench', 'RUQO2']\n",
      "S2 = ['Age']\n",
      "S3 = ['LVH', 'LVHreport']\n",
      "S4 = ['BirthAsphyxia']\n"
     ]
    }
   ],
   "source": [
    "partitions = get_partitions(child_model, set(child_model.nodes()) - set(patient1.keys()) - {target}, target, patient1)\n",
    "for i, part in enumerate(partitions, 1):\n",
    "    print(f\"S{i} = {sorted(part)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "203de66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_partitions(model, evidence, D, d_value, H, threshold):\n",
    "    \n",
    "    partitions = get_partitions(model, H, D, evidence)\n",
    "    inference = VariableElimination(model)\n",
    "    \n",
    "    # Get opposite state for D\n",
    "    d_states = model.get_cpds(D).state_names[D]\n",
    "    d_index = d_states.index(d_value)\n",
    "    not_d_value = d_states[1] if d_index == 0 else d_states[0]\n",
    "    \n",
    "    # 1. Compute Initial Log-Odds identically to the SDP function\n",
    "    dist_D = inference.query(variables=[D], evidence=evidence, show_progress=False)\n",
    "    p_d_e = dist_D.get_value(**{D: d_value})\n",
    "    p_not_d_e = dist_D.get_value(**{D: not_d_value})\n",
    "    \n",
    "    log_O_d_e = math.log(p_d_e / p_not_d_e) if p_not_d_e > 0 else float('inf')\n",
    "    lambda_threshold = math.log(threshold / (1 - threshold))\n",
    "    is_positive_decision = (log_O_d_e >= lambda_threshold)\n",
    "    \n",
    "    evidence_d = evidence.copy()\n",
    "    evidence_d[D] = d_value\n",
    "    \n",
    "    evidence_not_d = evidence.copy()\n",
    "    evidence_not_d[D] = not_d_value\n",
    "    \n",
    "    classifications = {}\n",
    "    \n",
    "    # 2. Evaluate each partition's bounds\n",
    "    for partition in partitions:\n",
    "        # Query the joint distribution\n",
    "        dist_S_given_d = inference.query(variables=partition, evidence=evidence_d, show_progress=False).values\n",
    "        dist_S_given_not_d = inference.query(variables=partition, evidence=evidence_not_d, show_progress=False).values\n",
    "        \n",
    "        # Identical weight calculation: Use the 1e-12 hard floor instead of additive epsilon\n",
    "        # Vectorized via numpy to strictly match the math of max(val, 1e-12) while preserving speed\n",
    "        p_s_d = np.maximum(dist_S_given_d, 1e-12)\n",
    "        p_s_not_d = np.maximum(dist_S_given_not_d, 1e-12)\n",
    "        \n",
    "        log_weights = np.log(p_s_d / p_s_not_d)\n",
    "        \n",
    "        # Extract the worst-case and best-case log-odds impact\n",
    "        w_min = np.min(log_weights)\n",
    "        w_max = np.max(log_weights)\n",
    "        swing = w_max - w_min\n",
    "        \n",
    "        # 3. Classify for Natural Language Generation in medical diagnostic systems\n",
    "        if is_positive_decision:\n",
    "            if log_O_d_e + w_min < lambda_threshold:\n",
    "                category = \"Potential Reverser\"\n",
    "                explanation = \"Some combination of these variables could change the current positive diagnosis.\"\n",
    "            else:\n",
    "                category = \"Stable\"\n",
    "                explanation = \"This group of variables cannot change the positive diagnosis.\"\n",
    "        else:\n",
    "            if log_O_d_e + w_max >= lambda_threshold:\n",
    "                category = \"Potential Reverser\"\n",
    "                explanation = \"Some combination of these variables could change the diagnosis.\"\n",
    "            else:\n",
    "                category = \"Stable\"\n",
    "                explanation = \"This group of variables is not enough to change the negative diagnosis.\"\n",
    "                \n",
    "        classifications[tuple(partition)] = {\n",
    "            \"category\": category,\n",
    "            \"explanation\": explanation,\n",
    "            \"w_min\": w_min,\n",
    "            \"w_max\": w_max,\n",
    "            \"swing\": swing\n",
    "        }\n",
    "        \n",
    "    return classifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc1081",
   "metadata": {},
   "source": [
    "investigar o efeito do maior w na direo contrria da deciso atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08764683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: ('DuctFlow', 'LungParench', 'LowerBodyO2', 'CO2', 'CardiacMixing', 'Grunting', 'LungFlow'), \n",
      "Category: Potential Reverser, Explanation: Some combination of these variables could change the current positive diagnosis., Swing: 2.0808\n",
      "Partition: ('Age',), \n",
      "Category: Stable, Explanation: This group of variables cannot change the positive diagnosis., Swing: 0.8056\n",
      "Partition: ('LVH',), \n",
      "Category: Stable, Explanation: This group of variables cannot change the positive diagnosis., Swing: 0.0000\n",
      "Partition: ('BirthAsphyxia',), \n",
      "Category: Stable, Explanation: This group of variables cannot change the positive diagnosis., Swing: 0.0000\n"
     ]
    }
   ],
   "source": [
    "classifications = classify_partitions(child_model, patient1, D=target, d_value=1, H=H_child, threshold=0.5)\n",
    "for part, info in classifications.items():\n",
    "    print(f\"Partition: {part}, \\nCategory: {info['category']}, Explanation: {info['explanation']}, Swing: {info['swing']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f41986f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap SDP estimates for patient 1: [0.66 0.82 0.75 0.72 0.78 0.71 0.74 0.69 0.73 0.79 0.8  0.79 0.76 0.75\n",
      " 0.79 0.71 0.81 0.71 0.73 0.77 0.82 0.77 0.8  0.77 0.75 0.78 0.75 0.75\n",
      " 0.81 0.73 0.79 0.82 0.72 0.71 0.74 0.73 0.75 0.82 0.67 0.76 0.7  0.77\n",
      " 0.72 0.78 0.78 0.85 0.74 0.78 0.72 0.82]\n"
     ]
    }
   ],
   "source": [
    "# estimation for patient 1\n",
    "sdp_estimates_patient1 = bootstrapped_sdp_estimation(child_model, D=target, d_value=1, evidence=patient1, threshold=0.7, n_samples=100, n_bootstraps=50)\n",
    "print(f\"Bootstrap SDP estimates for patient 1: {sdp_estimates_patient1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10090f5",
   "metadata": {},
   "source": [
    "## Interesting SDP pitfall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f6f3d",
   "metadata": {},
   "source": [
    "mostrar esse exemplo para discutir a robustez da deciso em funo do valor especfico de D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6483a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial P(D|e): 0.7318861968880331, P(not D|e): 0.26811380311196686\n",
      "Initial Log-Odds: 1.0042135042876585, Lambda: 0.8472978603872034, Current Decision Positive: True\n",
      "SDP for patient 2, dvalue = 1: 0.67921593093056\n",
      "Initial P(D|e): 0.26811380311196686, P(not D|e): 0.7318861968880331\n",
      "Initial Log-Odds: -1.0042135042876585, Lambda: -0.8472978603872036, Current Decision Positive: False\n",
      "SDP for patient 2, dvalue = 0: 0.67921593093056\n"
     ]
    }
   ],
   "source": [
    "patient2 = {'ChestXray': 1, 'CO2Report': 0, 'XrayReport': 1}\n",
    "target = 'Sick'\n",
    "H_child = ['DuctFlow', 'CO2', 'Age', 'BirthAsphyxia', \n",
    "           'LVHReport', 'LowerBodyO2', 'LungFlow', 'Grunting', 'LungParench', 'CardiacMixing', 'LVH']\n",
    "sdp_patient2 = optimized_tree_search_sdp(\n",
    "    child_model,\n",
    "    D=target,\n",
    "    d_value=1,\n",
    "    evidence=patient2,\n",
    "    threshold=0.7,\n",
    "    partitions=get_partitions(child_model, H_child, target, patient2)\n",
    ")\n",
    "print(f\"SDP for patient 2, dvalue = 1: {sdp_patient2}\")\n",
    "\n",
    "sdp_patient2 = optimized_tree_search_sdp(\n",
    "    child_model,\n",
    "    D=target,\n",
    "    d_value=0,\n",
    "    evidence=patient2,\n",
    "    threshold=0.3,\n",
    "    partitions=get_partitions(child_model, H_child, target, patient2)\n",
    ")\n",
    "print(f\"SDP for patient 2, dvalue = 0: {sdp_patient2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc20dff",
   "metadata": {},
   "source": [
    "# Testing ASIA network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8d43af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient1 = {'S': 0}\n",
    "target = 'B'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7d21e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(target=1 | evidence) for patient 1 in ASIA graph: 0.291393361160803\n"
     ]
    }
   ],
   "source": [
    "#P(D=1 | evidence) for patient 1\n",
    "inference_asia = VariableElimination(asia_graph)\n",
    "p_d_given_evidence_asia = inference_asia.query(variables=[target], evidence=patient1, show_progress=False).values[1]\n",
    "print(f\"P(target=1 | evidence) for patient 1 in ASIA graph: {p_d_given_evidence_asia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2670f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1 = ['A', 'D', 'E', 'L', 'T', 'X']\n"
     ]
    }
   ],
   "source": [
    "partitions = get_partitions(asia_graph, set(asia_graph.nodes()) - set(patient1.keys()) - {target}, target, patient1)\n",
    "for i, part in enumerate(partitions, 1):\n",
    "    print(f\"S{i} = {sorted(part)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6daed650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDP for patient 1 in ASIA graph: 0.7067478177073655\n"
     ]
    }
   ],
   "source": [
    "sdp_patient1_asia = exact_sdp_tree_search(asia_graph, D=target, d_value=1, evidence=patient1, threshold=0.5)\n",
    "print(f\"SDP for patient 1 in ASIA graph: {sdp_patient1_asia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "894370c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap SDP estimates for patient 1 in ASIA graph: [0.76 0.77 0.7  0.69 0.73 0.7  0.76 0.68 0.81 0.68 0.68 0.68 0.67 0.75\n",
      " 0.68 0.69 0.81 0.72 0.61 0.65 0.68 0.63 0.77 0.69 0.76 0.66 0.81 0.66\n",
      " 0.67 0.74 0.61 0.75 0.68 0.75 0.64 0.7  0.65 0.7  0.66 0.71 0.72 0.79\n",
      " 0.71 0.68 0.71 0.68 0.64 0.67 0.7  0.66]\n"
     ]
    }
   ],
   "source": [
    "# monte carlo\n",
    "sdp_estimates_patient1_asia = bootstrapped_sdp_estimation(asia_graph, D=target, d_value=1, evidence=patient1, threshold=0.5, n_samples=100, n_bootstraps=50)\n",
    "print(f\"Bootstrap SDP estimates for patient 1 in ASIA graph: {sdp_estimates_patient1_asia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f93c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_flipping_scenarios(model, D, d_value, evidence, threshold):\n",
    "    \"\"\"\n",
    "    Identifies the exact hidden variable scenarios that would flip the current decision.\n",
    "    \n",
    "    Returns a list of dictionaries containing:\n",
    "      - 'scenario': The specific hidden variable instantiation.\n",
    "      - 'prob_scenario': How likely this scenario is to happen, Pr(h|e).\n",
    "      - 'new_decision_prob': The new probability of the diagnosis, Pr(D|h,e).\n",
    "    \"\"\"\n",
    "    inference = VariableElimination(model)\n",
    "    \n",
    "    # 1. Identify hidden variables\n",
    "    all_vars = set(model.nodes())\n",
    "    observed_vars = set(evidence.keys())\n",
    "    H = list(all_vars - observed_vars - {D})\n",
    "    \n",
    "    # 2. Determine the CURRENT decision\n",
    "    current_dist = inference.query(variables=[D], evidence=evidence, show_progress=False)\n",
    "    d_index = model.get_cpds(D).state_names[D].index(d_value)\n",
    "    p_d_initial = current_dist.values[d_index]\n",
    "    \n",
    "    current_decision = p_d_initial >= threshold\n",
    "    \n",
    "    # 3. Setup state spaces for iteration\n",
    "    state_spaces = [model.get_cpds(var).state_names[var] for var in H]\n",
    "    all_assignments = list(itertools.product(*state_spaces))\n",
    "    \n",
    "    # Pre-compute Pr(h|e)\n",
    "    p_h_dist = inference.query(variables=H, evidence=evidence, show_progress=False)\n",
    "    \n",
    "    flipped_scenarios = []\n",
    "    \n",
    "    # 4. Evaluate each scenario\n",
    "    for assignment in all_assignments:\n",
    "        h_dict = dict(zip(H, assignment))\n",
    "        \n",
    "        # Pr(h|e)\n",
    "        p_h_given_e = p_h_dist.get_value(**h_dict)\n",
    "        if p_h_given_e == 0:\n",
    "            continue\n",
    "            \n",
    "        # Pr(D | e, h)\n",
    "        query_e_h = {**evidence, **h_dict}\n",
    "        p_d_given_e_h_dist = inference.query(variables=[D], evidence=query_e_h, show_progress=False)\n",
    "        p_d_given_e_h = p_d_given_e_h_dist.values[d_index]\n",
    "        \n",
    "        # 5. Check if the decision FLIPS\n",
    "        new_decision = p_d_given_e_h >= threshold\n",
    "        \n",
    "        if new_decision != current_decision:\n",
    "            flipped_scenarios.append({\n",
    "                'scenario': h_dict,\n",
    "                'prob_scenario': p_h_given_e,\n",
    "                'new_decision_prob': p_d_given_e_h\n",
    "            })\n",
    "            \n",
    "    # Sort the flipped scenarios by how likely they are to occur (highest probability first)\n",
    "    flipped_scenarios.sort(key=lambda x: x['prob_scenario'], reverse=True)\n",
    "    \n",
    "    return {\n",
    "        'current_prob': p_d_initial,\n",
    "        'current_decision': current_decision,\n",
    "        'threshold': threshold,\n",
    "        'flipping_scenarios': flipped_scenarios\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd58f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = get_decision_flipping_scenarios(asia_graph, D='B', d_value=1, evidence=patient1, threshold=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8376d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.291393361160803"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios['current_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57d2770e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios['current_decision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f71ca39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'scenario': {'T': 0, 'X': 0, 'A': 0, 'D': 1, 'E': 0, 'L': 0},\n",
       "  'prob_scenario': 0.27606281971029745,\n",
       "  'new_decision_prob': 0.7805916555867882},\n",
       " {'scenario': {'T': 0, 'X': 1, 'A': 0, 'D': 1, 'E': 0, 'L': 0},\n",
       "  'prob_scenario': 0.014613078642171394,\n",
       "  'new_decision_prob': 0.780591655586788},\n",
       " {'scenario': {'T': 0, 'X': 0, 'A': 1, 'D': 1, 'E': 0, 'L': 0},\n",
       "  'prob_scenario': 0.002446767045109604,\n",
       "  'new_decision_prob': 0.7805916555867882},\n",
       " {'scenario': {'T': 0, 'X': 1, 'A': 1, 'D': 1, 'E': 0, 'L': 0},\n",
       "  'prob_scenario': 0.00012951689505592004,\n",
       "  'new_decision_prob': 0.7805916555867881}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios['flipping_scenarios'][:5]  # top 5 most likely flipping scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d688f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = classify_partitions(asia_graph, patient1, D=target, d_value=1, H=set(asia_graph.nodes()) - set(patient1.keys()) - {target}, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1daf95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition classifications for ASIA graph:\n",
      "Partition: ('L', 'T'), Category: Stable, Explanation: This group of variables is not enough to change the negative diagnosis., Swing: 0.0000\n",
      "Partition: ('B', 'D'), Category: Stable, Explanation: This group of variables is not enough to change the negative diagnosis., Swing: 0.0000\n",
      "Partition: ('X',), Category: Stable, Explanation: This group of variables is not enough to change the negative diagnosis., Swing: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Partition classifications for ASIA graph:\")\n",
    "for part, info in classifications.items():\n",
    "    print(f\"Partition: {part}, Category: {info['category']}, Explanation: {info['explanation']}, Swing: {info['swing']:.4f}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0171a203",
   "metadata": {},
   "source": [
    "# Explaining the current evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ebf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the variables inside e by their individual impact, comparing P(D|e) vs P(D|e - {var})\n",
    "def rank_evidence_variables(model, D, d_value, evidence, threshold):\n",
    "    inference = VariableElimination(model)\n",
    "    \n",
    "    # Get opposite state for D\n",
    "    d_states = model.get_cpds(D).state_names[D]\n",
    "    d_index = d_states.index(d_value)\n",
    "    not_d_value = d_states[1] if d_index == 0 else d_states[0]\n",
    "    \n",
    "    # Compute baseline probability with all evidence\n",
    "    dist_full = inference.query(variables=[D], evidence=evidence, show_progress=False)\n",
    "    p_d_full = dist_full.values[d_index]\n",
    "    \n",
    "    variable_impact = []\n",
    "    \n",
    "    for var in evidence.keys():\n",
    "        reduced_evidence = {k: v for k, v in evidence.items() if k != var}\n",
    "        dist_reduced = inference.query(variables=[D], evidence=reduced_evidence, show_progress=False)\n",
    "        p_d_reduced = dist_reduced.values[d_index]\n",
    "        \n",
    "        impact = abs(p_d_full - p_d_reduced)\n",
    "        variable_impact.append((var, impact))\n",
    "        \n",
    "    variable_impact.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return variable_impact\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bn-medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
